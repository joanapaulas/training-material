<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <title>Galaxy Training!</title>
        <link rel="stylesheet" href="/training-material/assets/css/bootstrap.min.css?v=3">
        <link rel="stylesheet" href="/training-material/assets/css/main.css?v=2">
        <link rel="stylesheet" href="/training-material/assets/css/font-awesome.css">
        <link rel="stylesheet" href="/training-material/assets/css/academicons.css">
        <link rel="stylesheet" href="/training-material/assets/css/syntax_highlighting.css">
        <link rel="shortcut icon" href="/training-material/favicon.ico" type="image/x-icon" />
    </head>
    <body>
        




<header>
    <nav class="navbar navbar-expand-lg navbar-dark">
        <div class="container">
            <a class="navbar-brand" href="/training-material/">
                <img src="/training-material/assets/images/GTN-60px.png" height="30" alt="Galaxy Training Network logo">
                Galaxy Training!
            </a>

            <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#top-navbar" aria-controls="top-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="top-navbar">
                <ul class="navbar-nav">
                    <li class="nav-item">
                        <a class="nav-link" href="/training-material/topics/metagenomics" title="Go back to list of tutorials">
                            <i class="fa fa-folder-o" aria-hidden="true"></i> Metagenomics
                        </a>
                    </li>

                    
                        
                        
                        
                            <li class="nav-item dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Introduction slides">
                                    <i class="fa fa-slideshare" aria-hidden="true"></i> Introduction slides
                                </a>
                                <div class="dropdown-menu">
                                    
                                        
                                            
                                                <a class="dropdown-item" href="/training-material/topics/metagenomics/slides/introduction.html">
                                                    Introduction to metagenomics
                                                </a>
                                            
                                        
                                    
                                        
                                            
                                        
                                    
                                        
                                            
                                        
                                    
                                </div>
                            </li>
                        
                    

                    
                        <li class="nav-item dropdown">
                            <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Where to run the tutorial">
                                <i class="fa fa-cog" aria-hidden="true"></i> Galaxy Instances
                            </a>
                            <div class="dropdown-menu">
                                
                                    <a class="dropdown-item" href="https://github.com/galaxyproject/training-material/tree/master/topics/metagenomics/docker" title="Docker image for this tutorial">
                                        <i class="fa fa-ship" aria-hidden="true"></i> Docker image
                                    </a>
                                
                                
                                
                            </div>
                        </li>
                    

                    

                    
                    <li class="nav-item">
                        <a class="nav-link" href="https://doi.org/10.5281/zenodo.165147" title="Links to data">
                            <i class="fa fa-files-o" aria-hidden="true"></i> Input Dataset
                        </a>
                    </li>
                    

                    
                    <li class="nav-item">
                        <a class="nav-link" href="/training-material/topics/metagenomics#references" title="References">
                            <i class="fa fa-book" aria-hidden="true"></i> Literature
                        </a>
                    </li>
                    

                    <li class="nav-item dropdown">
    <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-expanded="false" title="Help">
        <i class="fa fa-life-ring" aria-hidden="true"></i> Help
    </a>
    <div class="dropdown-menu">
        <a class="dropdown-item" href="https://gitter.im/Galaxy-Training-Network/Lobby" title="Chat on Gitter">
            Gitter
        </a>
        <a class="dropdown-item" href="https://biostar.usegalaxy.org/" title="Ask on Biostars">
            Biostars
        </a>
    </div>
</li>


                    <li class="nav-item">
                        <a class="nav-link" href="https://github.com/galaxyproject/training-material/tree/master/topics/metagenomics/tutorials/mothur-miseq-sop/tutorial.md">
                            <i class="fa fa-github" aria-hidden="true"></i> Edit
                        </a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
</header>

<div class="container main-content">
    <section class="tutorial">
        <h1>16S Microbial Analysis with Mothur</h1>

        <blockquote class="overview">
            <h3>Overview</h3>

            <strong><i class="fa fa-question-circle" aria-hidden="true"></i> Questions</strong>
            <ul>
            
            <li>What is the effect of normal variation in the gut microbiome on host health?</li>
            
            </ul>

            <strong><i class="fa fa-bullseye" aria-hidden="true"></i> Objectives</strong>
            <ul>
            
            <li>Analyze of 16S rRNA sequencing data using the Mothur toolsuite in Galaxy</li>
            
            </ul>

            
            <strong><i class="fa fa-check-circle" aria-hidden="true"></i> Requirements</strong>
            <ul>
            
                <li>
                    
                    <a href="/training-material/topics//introduction/">Galaxy introduction</a>
                    
                </li>
            
            
            </ul>
            

            <p><strong><i class="fa fa-hourglass-end" aria-hidden="true"></i> Time estimation:</strong> 3-4h</p>
        </blockquote>

        <h1 class="no_toc" id="overview">Overview</h1>

<p>In this tutorial we will perform the
<a href="https://www.mothur.org/wiki/MiSeq_SOP">Standard Operating Procedure (SOP) for MiSeq data</a>, developed by the
creators of the Mothur software package, the <a href="http://www.schlosslab.org/">Schloss lab</a>, within Galaxy.</p>

<blockquote class="agenda">
  <h3 id="agenda">Agenda</h3>

  <p>In this tutorial, we will:</p>

<ol id="markdown-toc">
  <li><a href="#obtaining-and-preparing-data" id="markdown-toc-obtaining-and-preparing-data">Obtaining and preparing data</a>    <ol>
      <li><a href="#understanding-our-input-data" id="markdown-toc-understanding-our-input-data">Understanding our input data</a></li>
      <li><a href="#importing-the-data-into-galaxy" id="markdown-toc-importing-the-data-into-galaxy">Importing the data into Galaxy</a></li>
    </ol>
  </li>
  <li><a href="#quality-control" id="markdown-toc-quality-control">Quality Control</a>    <ol>
      <li><a href="#reducing-sequencing-and-pcr-errors" id="markdown-toc-reducing-sequencing-and-pcr-errors">Reducing sequencing and PCR errors</a></li>
      <li><a href="#processing-improved-sequences" id="markdown-toc-processing-improved-sequences">Processing improved sequences</a></li>
      <li><a href="#assessing-error-rates-based-on-our-mock-community" id="markdown-toc-assessing-error-rates-based-on-our-mock-community">Assessing error rates based on our mock community</a></li>
      <li><a href="#preparing-for-analysis" id="markdown-toc-preparing-for-analysis">Preparing for analysis</a></li>
    </ol>
  </li>
  <li><a href="#otu-based-analysis" id="markdown-toc-otu-based-analysis">OTU-based Analysis</a>    <ol>
      <li><a href="#calculate-species-diversity" id="markdown-toc-calculate-species-diversity">Calculate Species Diversity</a></li>
    </ol>
  </li>
  <li><a href="#visualisations" id="markdown-toc-visualisations">Visualisations</a>    <ol>
      <li><a href="#phinch" id="markdown-toc-phinch">Phinch</a></li>
      <li><a href="#krona" id="markdown-toc-krona">Krona</a></li>
    </ol>
  </li>
  <li><a href="#extra-credit" id="markdown-toc-extra-credit">Extra Credit</a>    <ol>
      <li><a href="#determine-statistical-significance-of-clusterings" id="markdown-toc-determine-statistical-significance-of-clusterings">Determine statistical significance of clusterings</a></li>
      <li><a href="#population-level-analysis" id="markdown-toc-population-level-analysis">Population-level Analysis</a></li>
    </ol>
  </li>
</ol>

</blockquote>

<blockquote class="comment">
  <h3 id="-note"><i class="fa fa-commenting-o" aria-hidden="true"></i> Note</h3>
  <p>Each of the Mothur tools in Galaxy contains a link to the mothur wiki in the help section. Here you can find
more details about all the inputs, outputs and parameters for the tool.
<br /><br />
Your results may deviate slightly from the ones presented in this tutorial due to differing tool or
reference data versions or stochastic processes in the algorithms.</p>
</blockquote>

<h1 id="obtaining-and-preparing-data">Obtaining and preparing data</h1>

<p>In this tutorial we use 16S rRNA data, but similar pipelines can be used for WGS data.</p>

<blockquote class="tip">
  <h3 id="-background-the-16s-ribosomal-rna-gene"><i class="fa fa-lightbulb-o" aria-hidden="true"></i> Background: The 16S ribosomal RNA gene</h3>
  <p><img src="../../images/16S_gene.png" alt="The 16S ribosomal RNA gene" /> <br /><br /></p>

  <p>The 16S rRNA gene has several properties that make it ideally suited for our purposes</p>

  <ol>
    <li>Present in all prokaryotes</li>
    <li>Highly conserved + highly variable regions</li>
    <li>Huge reference databases</li>
  </ol>

  <p><img src="../../images/16S_variableregions.jpg" alt="16S Variable regions" /></p>

  <p>The highly conserved regions make it easy to target the gene across different organisms,
while the highly variable regions allow us to distinguish between different species.</p>

  <p>(slide credit <a href="https://www.slideshare.net/beiko/ccbc-tutorial-beiko">https://www.slideshare.net/beiko/ccbc-tutorial-beiko </a>)</p>
</blockquote>

<h2 id="understanding-our-input-data">Understanding our input data</h2>
<p>In this tutorial we are interested in understanding the effect of normal variation in the gut microbiome on host health.
To that end, fresh feces from mice were collected on a daily basis for 365 days post weaning. During the first 150 days
post weaning (dpw), nothing was done to our mice except allow them to eat, get fat, and be merry. We were curious whether
the rapid change in weight observed during the first 10 dpw affected the stability microbiome compared to the microbiome
observed between days 140 and 150. We will address this question in this tutorial using a combination of OTU, phylotype,
and phylogenetic methods.</p>

<p><img src="../../images/experiment_setup.png" alt="Experiment setup" /></p>

<p>To make this tutorial easier to execute, we are providing only part of the data - you are given the flow files for one
animal at 10 time points (5 early and 5 late). In order to assess the error rate of our analysis pipeline and experimental
setup, we additionally resequenced a mock community composed of genomic DNA from 21 bacterial strains.</p>

<blockquote class="comment">
  <h3 id="-dataset-details"><i class="fa fa-commenting-o" aria-hidden="true"></i> Dataset details</h3>
  <p>Because of the large size of the original dataset (3.9 GB) you are given 20 of the 362 pairs of fastq
files. For example, you will see two files: <code class="highlighter-rouge">F3D0_S188_L001_R1_001.fastq</code>, and
<code class="highlighter-rouge">F3D0_S188_L001_R2_001.fastq</code>
<br /><br />
These two files correspond to Female 3 on Day 0 (F3D0) (i.e. the day of weaning). The first file
(and all those with R1 in the name) correspond to the forward reads, while the second (and all
those with R2 in the name) correspond to the reverse reads.
<br /><br />
These sequences are 250 bp and overlap in the V4 region of the 16S rRNA gene; this region is about
253 bp long. Looking at the datasets, you will see 22 fastq files, representing 10 time points from
Female 3 and 1 mock community. You will also see <code class="highlighter-rouge">HMP_MOCK.v35.fasta</code> which contains the sequences used
in the mock community that were sequenced in fasta format.</p>
</blockquote>

<!-- note: mothur seems to have forgotten day 4 in their SOP example data, therefore this description and results
in this document differ slightly from the description on their website -->

<h2 id="importing-the-data-into-galaxy">Importing the data into Galaxy</h2>

<p>Now that we know what our input data is, let’s get it into our Galaxy history:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-obtaining-our-data"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Obtaining our data</h3>

  <ol>
    <li>
      <p>Make sure you have an empty analysis history. Give it a name.</p>

      <blockquote class="tip">
        <h3 id="-starting-a-new-history"><i class="fa fa-lightbulb-o" aria-hidden="true"></i> Starting a new history</h3>

        <ul>
          <li>Click the <strong>gear icon</strong> at the top of the history panel</li>
          <li>Select the option <strong>Create New</strong> from the menu</li>
        </ul>
      </blockquote>
    </li>
    <li><strong>Import Sample Data.</strong> The data for this course may be available from a shared library in Galaxy
(ask your instructor). If this is not the case, you can upload it yourself.
      <ul>
        <li>Option 1: From data library:
          <ul>
            <li>Navigate to the shared data library, you should find 20 pairs of fastq files; 19 from the mice,
and one pair from the mock community.</li>
          </ul>
        </li>
        <li>Option 2: From your Zenodo:
          <ul>
            <li>Data is available from Zenodo here: <a href="https://doi.org/10.5281/zenodo.800651"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.800651.svg" alt="DOI" /></a></li>
            <li>In the file upload menu choose the <code class="highlighter-rouge">Paste/Fetch data</code> option and enter the following urls to import the file from Zenodo to Galaxy directly</li>
          </ul>
        </li>
      </ul>
      <details>
<summary> Click to view Zenodo URLs</summary>
<pre>
https://zenodo.org/record/800651/files/F3D0_R1.fastq
https://zenodo.org/record/800651/files/F3D0_R2.fastq
https://zenodo.org/record/800651/files/F3D141_R1.fastq
https://zenodo.org/record/800651/files/F3D141_R2.fastq
https://zenodo.org/record/800651/files/F3D142_R1.fastq
https://zenodo.org/record/800651/files/F3D142_R2.fastq
https://zenodo.org/record/800651/files/F3D143_R1.fastq
https://zenodo.org/record/800651/files/F3D143_R2.fastq
https://zenodo.org/record/800651/files/F3D144_R1.fastq
https://zenodo.org/record/800651/files/F3D144_R2.fastq
https://zenodo.org/record/800651/files/F3D145_R1.fastq
https://zenodo.org/record/800651/files/F3D145_R2.fastq
https://zenodo.org/record/800651/files/F3D146_R1.fastq
https://zenodo.org/record/800651/files/F3D146_R2.fastq
https://zenodo.org/record/800651/files/F3D147_R1.fastq
https://zenodo.org/record/800651/files/F3D147_R2.fastq
https://zenodo.org/record/800651/files/F3D148_R1.fastq
https://zenodo.org/record/800651/files/F3D148_R2.fastq
https://zenodo.org/record/800651/files/F3D149_R1.fastq
https://zenodo.org/record/800651/files/F3D149_R2.fastq
https://zenodo.org/record/800651/files/F3D150_R1.fastq
https://zenodo.org/record/800651/files/F3D150_R2.fastq
https://zenodo.org/record/800651/files/F3D1_R1.fastq
https://zenodo.org/record/800651/files/F3D1_R2.fastq
https://zenodo.org/record/800651/files/F3D2_R1.fastq
https://zenodo.org/record/800651/files/F3D2_R2.fastq
https://zenodo.org/record/800651/files/F3D3_R1.fastq
https://zenodo.org/record/800651/files/F3D3_R2.fastq
https://zenodo.org/record/800651/files/F3D5_R1.fastq
https://zenodo.org/record/800651/files/F3D5_R2.fastq
https://zenodo.org/record/800651/files/F3D6_R1.fastq
https://zenodo.org/record/800651/files/F3D6_R2.fastq
https://zenodo.org/record/800651/files/F3D7_R1.fastq
https://zenodo.org/record/800651/files/F3D7_R2.fastq
https://zenodo.org/record/800651/files/F3D8_R1.fastq
https://zenodo.org/record/800651/files/F3D8_R2.fastq
https://zenodo.org/record/800651/files/F3D9_R1.fastq
https://zenodo.org/record/800651/files/F3D9_R2.fastq
https://zenodo.org/record/800651/files/Mock_R1.fastq
https://zenodo.org/record/800651/files/Mock_R2.fastq
</pre>
</details>
      <p><br /></p>
    </li>
    <li><strong>Import Reference Data.</strong>  Go back to the data library and import the following reference
datasets, or import them from Zenodo:
      <ul>
        <li><code class="highlighter-rouge">silva.v4.fasta</code></li>
        <li><code class="highlighter-rouge">HMP_MOCK.v35.fasta</code></li>
        <li><code class="highlighter-rouge">mouse.dpw.metadata</code></li>
        <li><code class="highlighter-rouge">mouse.time.design</code></li>
        <li><code class="highlighter-rouge">trainset9_032012.pds.fasta</code></li>
        <li><code class="highlighter-rouge">trainset9_032012.pds.tax</code></li>
      </ul>

      <details>
<summary>Click to view Zenodo URLs</summary>
<pre>
https://zenodo.org/record/800651/files/HMP_MOCK.v35.fasta
https://zenodo.org/record/800651/files/mouse.dpw.metadata
https://zenodo.org/record/800651/files/mouse.time.design
https://zenodo.org/record/800651/files/silva.v4.fasta
https://zenodo.org/record/800651/files/trainset9_032012.pds.fasta
https://zenodo.org/record/800651/files/trainset9_032012.pds.tax
</pre>
</details>
    </li>
  </ol>
</blockquote>

<p>Now that’s a lot of files to manage. Luckily Galaxy can make life a bit easier by allowing us to create
<em>dataset collections</em>. This enables us to easily run tools on multiple datasets at once. Let’s
create a collection now:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-organizing-our-data-into-a-collection"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Organizing our data into a collection</h3>

  <p>Since we have paired-end data, each sample consist of two separate fastq files, one containing the
forward reads, and one containing the reverse reads. We can recognize the pairing from the file names,
which will differ only by <code class="highlighter-rouge">_R1</code> or <code class="highlighter-rouge">_R2</code> in the filename. We can tell Galaxy about this paired naming
convention, so that our tools will know which files belong together.</p>

  <ol>
    <li>
      <p>Click on the <strong>checkmark icon</strong> at top of your history.
  <img src="../../../../shared/images/history_menu_buttons2.png" alt="Checkmark icon in history menu" /></p>
    </li>
    <li>Select all the fastq files (40 in total), then click on <strong>for all selected..</strong> and select
  <strong>Build List of Dataset Pairs</strong> from the dropdown menu.</li>
    <li>
      <p>In the next dialog window you can create the list of pairs. By default Galaxy will look for pairs
  of files that differ only by a <code class="highlighter-rouge">_1</code> and <code class="highlighter-rouge">_2</code> part in their names. In our case however, these
  should be <code class="highlighter-rouge">_R1</code> and <code class="highlighter-rouge">_R2</code>. Please change these values accordingly. You should now see a list of
  pairs suggested by Galaxy,
  <img src="../../images/create_collection.png" alt="List of suggested paired datasets" /> <br /><br /></p>
    </li>
    <li>
      <p>Examine the pairings, if it looks good, you can click on <strong>auto-pair</strong> to create the suggested
  pairs.
  <img src="../../images/create_collection2.png" alt="The result of pairing" /> <br /><br />
  The middle segment is the name for each pair. You can change these names by clicking on them. These
  names will be used as sample names in the downstream analysis so always make sure they are
  informative.
  <strong>Important:</strong> Make sure these sample names contain only alphanumeric characters. If you’ve
  imported the data from Zenodo, the sample names will default to the full url, please change these
  values to only their last part, e.g. <code class="highlighter-rouge">F3D0</code>, <code class="highlighter-rouge">F3D5</code> etc.</p>
    </li>
    <li>Once you are happy with your pairings, enter a name for your new collection at the bottom right of
  the screen. Then click the <strong>Create List</strong> button. A new dataset collection item will now appear in
  your history.</li>
  </ol>
</blockquote>

<h1 id="quality-control">Quality Control</h1>

<h2 id="reducing-sequencing-and-pcr-errors">Reducing sequencing and PCR errors</h2>

<p>The first thing we want to do is combine our forward and reverse reads for each sample. This is done
using the <code class="highlighter-rouge">make.contigs</code> command, which requires the paired collection as input. This command will extract
the sequence and quality score data from your fastq files, create the reverse complement of the reverse
read and then join the reads into contigs. Then we will combine all samples into a single fasta file,
remembering which reads came from which samples using a <em>group</em> file.</p>

<blockquote class="comment">
  <h3 id="-algorithm-details"><i class="fa fa-commenting-o" aria-hidden="true"></i> Algorithm details</h3>
  <p>We have a very simple algorithm to do this. First, we align the pairs of sequences. Next, we look
across the alignment and identify any positions where the two reads disagree. If one sequence has a
base and the other has a gap, the quality score of the base must be over 25 to be considered real. If
both sequences have a base at that position, then we require one of the bases to have a quality score
6 or more points better than the other. If it is less than 6 points better, then we set the consensus
base to an N.</p>
</blockquote>

<h3 id="merging-our-data">Merging our data</h3>

<h4 id="make-contigs-from-paired-end-reads">Make contigs from paired-end reads</h4>

<p>In this experiment we used paired-end sequencing, this means sequencing was done from from both ends of each
fragment, resulting in an overlap in the middle. We will now combine these pairs of reads into <em>contigs</em>.</p>

<p><img src="../../images/16S_merge_contigs.png" alt="Merging into contigs" /></p>

<blockquote class="hands_on">
  <h3 id="-hands-on-combine-forward-and-reverse-reads-into-contigs"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Combine forward and reverse reads into contigs</h3>

  <ul>
    <li><strong>Make.contigs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Way to provide files” to <code class="highlighter-rouge">Multiple pairs - Combo mode</code></li>
        <li>“Fastq pairs” to the collection you just created</li>
        <li>Leave all other parameters to the default settings <br /><br /></li>
      </ul>
    </li>
  </ul>

</blockquote>

<p>This step merges the forward and reverse reads into contigs for each pair, and
then combines the results into a single fasta file. To retain information about
which reads originated from which samples, it also made a group file. View that
file now, it should look something like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>M00967_43_000000000-A3JHG_1_1101_10011_3881     F3D0
M00967_43_000000000-A3JHG_1_1101_10050_15564    F3D0
M00967_43_000000000-A3JHG_1_1101_10051_26098    F3D0
</code></pre>
</div>

<p>Here the first column contains the read name, and the second column contains the sample name.</p>

<h3 id="data-cleaning">Data Cleaning</h3>

<p>For more information on the topic of quality control, please see our training materials
<a href="/training-material/topics/sequence-analysis/">here</a></p>

<p>Next we want to improve the quality of our data. But first, let’s get a feel of our data</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-summarize-data"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Summarize data</h3>

  <ul>
    <li><strong>Summary.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” parameter to the <code class="highlighter-rouge">trim.contigs.fasta</code> file created by the make.contigs tool</li>
        <li>“Output logfile?” to <code class="highlighter-rouge">yes</code></li>
      </ul>
    </li>
  </ul>

</blockquote>

<p>The <code class="highlighter-rouge">summary</code> output files give information per read. The <code class="highlighter-rouge">logfile</code> outputs also contain some summary
statistics:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>             Start    End        NBases     Ambigs   Polymer  NumSeqs
Minimum:     1        248        248        0        3        1
2.5%-tile:   1        252        252        0        3        3810
25%-tile:    1        252        252        0        4        38091
Median:      1        252        252        0        4        76181
75%-tile:    1        253        253        0        5        114271
97.5%-tile:  1        253        253        6        6        148552
Maximum:     1        502        502        249      243      152360
Mean:        1        252.811    252.811    0.70063  4.44854
# of Seqs:   152360
</code></pre>
</div>

<p>This tells us that we have 152,360 sequences that for the most part vary between 248 and 253 bases.
Interestingly, the longest read in the dataset is 502 bp. Be suspicious of this. Recall that the reads
are supposed to be 251 bp each. This read clearly didn’t assemble well (or at all). Also, note that at
least 2.5% of our sequences had some ambiguous base calls. We’ll take care of these issues in the next
step when we run <code class="highlighter-rouge">screen.seqs</code>.</p>

<p>The following tool will remove any sequences with ambiguous bases (<code class="highlighter-rouge">maxambig</code> parameter) and anything longer than 275 bp (<code class="highlighter-rouge">maxlength</code> parameter).</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-filter-reads-based-on-quality-and-length"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Filter reads based on quality and length</h3>

  <ul>
    <li><strong>Screen.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” to the <code class="highlighter-rouge">trim.contigs.fasta</code> file created by the make.contigs tool</li>
        <li>“group” the group file created in the make.contigs step</li>
        <li>“maxlength” parameter to <code class="highlighter-rouge">275</code></li>
        <li>“maxambig” parameter to <code class="highlighter-rouge">0</code></li>
      </ul>
    </li>
  </ul>

  <blockquote class="question">
    <h3 id="-question"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

    <p>How many reads were removed in this screening step? (Hint: run the summary.seqs tool again)</p>

    <details>
   <summary>Click to view answer</summary>
   23,488. <br />
   This can be determined by looking at the number of lines in bad.accnos output of screen.seqs
   or by comparing the total number of seqs between of the summary log before and after this screening
   step
   </details>
  </blockquote>
</blockquote>

<h2 id="processing-improved-sequences">Processing improved sequences</h2>

<h3 id="optimize-files-for-computation">Optimize files for computation</h3>
<p>Because we are sequencing many of the same organisms, we anticipate that many of our sequences are
duplicates of each other. Because it’s computationally wasteful to align the same thing a bazillion
times, we’ll unique our sequences using the <code class="highlighter-rouge">unique.seqs</code> command:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-remove-duplicate-sequences"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Remove duplicate sequences</h3>

  <ul>
    <li><strong>Unique.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” to the <code class="highlighter-rouge">good.fasta</code> output from Screen.seqs</li>
        <li>“output format” to <code class="highlighter-rouge">Name File</code></li>
      </ul>
    </li>
  </ul>

  <blockquote class="question">
    <h3 id="-question-1"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

    <p>How many sequences were unique? how many duplicates were removed?</p>

    <details>
   <summary>Click to view answer</summary>
   16,426 unique sequences and 112,446 duplicates. <br />
   This can be determined from the number of lines in the fasta (or names) output, compared to the
   number of lines in the fasta file before this step.
   </details>
  </blockquote>
</blockquote>

<p>This tool outputs two files, one is a fasta file containing only the unique sequences, and a <em>names files</em>.
The names file consists of two columns, the first contains the sequence names for each of the unique
sequences, and the second column contains all other sequence names that are identical to the representative
sequence in the first column.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>name          representatives
read_name1    read_name2,read_name,read_name5,read_name11
read_name4    read_name6,read_name,read_name10
read_name7    read_name8
...
</code></pre>
</div>

<p>To reduce file sizes further and streamline analysis, we can now summarize the data in a <em>count table</em>.</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-generate-count-table"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Generate count table</h3>

  <ul>
    <li><strong>Count.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“name” to the <code class="highlighter-rouge">names</code> output from Unique.seqs</li>
        <li>“Use a Group file” to <code class="highlighter-rouge">yes</code></li>
        <li>“group” to the group file we created using the Screen.seqs tool</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>The <em>count_table</em> output will look something like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Representative_Sequence                      total   F3D0   F3D1  F3D141  F3D142  ...
M00967_43_000000000-A3JHG_1_1101_14069_1827  4402    370    29    257     142
M00967_43_000000000-A3JHG_1_1101_18044_1900  28      1      0     1       0
M00967_43_000000000-A3JHG_1_1101_13234_1983  10522   425    281   340     205
...
</code></pre>
</div>

<p>The first column contains the read names of the representative sequence, and the subsequent columns contain
the number of duplicates of this sequence observed in each sample.</p>

<h3 id="sequence-alignment">Sequence Alignment</h3>

<p>For more information on the topic of alignment, please see our training materials
<a href="/training-material/topics/sequence-analysis/">here</a></p>

<p>We are now ready to align our sequences to the reference. This step is an important
step to perform to improve the clustering of your OTUs <a href="https://doi.org/10.1038/ismej.2012.102">[Schloss 2013]</a></p>

<blockquote class="hands_on">
  <h3 id="-hands-on-align-sequences"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Align sequences</h3>

  <ol>
    <li><strong>Align.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” to the fasta output from Unique.seqs</li>
        <li>“reference” to the <code class="highlighter-rouge">silva.v4.fasta</code> reference file
<br /><br /></li>
      </ul>
    </li>
    <li><strong>Summary.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” parameter to the aligned output from previous step</li>
        <li>“count” parameter to <code class="highlighter-rouge">count_table</code> output from Count.seqs</li>
        <li>“Output logfile?” to <code class="highlighter-rouge">yes</code></li>
      </ul>
    </li>
  </ol>

</blockquote>

<p>Have a look at the summary output (log file):</p>

<div class="highlighter-rouge"><pre class="highlight"><code>            Start    End      NBases  Ambigs   Polymer  NumSeqs
Minimum:    1250     10693    250     0        3        1
2.5%-tile:  1968     11550    252     0        3        3222
25%-tile:   1968     11550    252     0        4        32219
Median:     1968     11550    252     0        4        64437
75%-tile:   1968     11550    253     0        5        96655
97.5%-tile: 1968     11550    253     0        6        125651
Maximum:    1982     13400    270     0        12       128872
Mean:       1967.99  11550    252.462 0        4.36693
# of unique seqs:   16426
total # of seqs:    128872
</code></pre>
</div>

<p>So what does this mean? You’ll see that the bulk of the sequences start at position 1968 and end at position 11550.
Some sequences start at position 1250 or 1982 and end at 10693 or 13400. These deviants from the mode positions
are likely due to an insertion or deletion at the terminal ends of the alignments. Sometimes you’ll see sequences
that start and end at the same position indicating a very poor alignment, which is generally due to non-specific
amplification.</p>

<h3 id="more-data-cleaning">More Data Cleaning</h3>

<p>To make sure that everything overlaps the same region we’ll re-run screen.seqs to get sequences that
start at or before position 1968 and end at or after position 11550. We’ll also set the maximum
homopolymer length to 8 (<code class="highlighter-rouge">maxhomop</code> parameter) since there’s nothing in the database with a stretch of 9 or more of the same
base in a row (this also could have been done in the first execution of <code class="highlighter-rouge">screen.seqs</code> above).</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-remove-poorly-aligned-sequences"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Remove poorly aligned sequences</h3>

  <ul>
    <li><strong>Screen.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” to the aligned fasta file</li>
        <li>“start” to 1968</li>
        <li>“end” to 11550</li>
        <li>“maxhomop” to 8</li>
        <li>“count” to our most recent count_table</li>
      </ul>
    </li>
  </ul>

  <p><strong>Note:</strong> we supply the count table so that it can be updated for the sequences we’re removing.</p>

  <blockquote class="question">
    <h3 id="-question-2"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

    <p>How many sequences were removed in this step?</p>
    <details>
  <summary> Click to view answer</summary>
  128 sequences were removed. This is the number of lines in the bad.accnos output.
</details>
  </blockquote>
</blockquote>

<p>Now we know our sequences overlap the same alignment coordinates, we want to make sure they <em>only</em> overlap
that region. So we’ll filter the sequences to remove the overhangs at both ends. Since we’ve done
paired-end sequencing, this shouldn’t be much of an issue. In addition, there are many
columns in the alignment that only contain gap characters (i.e. “.”). These can be pulled out without
losing any information. We’ll do all this with filter.seqs:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-filter-sequences"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Filter sequences</h3>

  <ul>
    <li><strong>Filter.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta”” to good.fasta output from Sreen.seqs</li>
        <li>“Vertical” to <code class="highlighter-rouge">yes</code></li>
        <li>“trump” to <code class="highlighter-rouge">.</code></li>
        <li>“Output logfile” to <code class="highlighter-rouge">yes</code></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>In the log file we see the following information:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Length of filtered alignment: 376
Number of columns removed: 13049
Length of the original alignment: 13425
Number of sequences used to construct filter: 16298
</code></pre>
</div>

<p>This means that our initial alignment was 13425 columns wide and that we were able to remove 13049 terminal gap
characters using <code class="highlighter-rouge">trump=.</code> and vertical gap characters using <code class="highlighter-rouge">vertical=yes</code>. The final alignment length is 376
columns. Because we’ve perhaps created some redundancy across our sequences by trimming the ends, we can re-run
<code class="highlighter-rouge">unique.seqs</code>:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-re-obtain-unique-sequences"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Re-obtain unique sequences</h3>

  <ul>
    <li><strong>Unique.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” to the <code class="highlighter-rouge">filtered fasta</code> output from Filter.seqs</li>
        <li>“name file or count table” to the count table from the last Screen.seqs</li>
      </ul>
    </li>
  </ul>

  <blockquote class="question">
    <h3 id="-question-3"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

    <p>How many duplicate sequences did our filter step produce?</p>
    <details>
  <summary> Click to view answer</summary>
  3. The number of unique sequences was reduced from 16298 to 16295
</details>
  </blockquote>
</blockquote>

<h3 id="pre-clustering">Pre-clustering</h3>
<p>The next thing we want to do to further de-noise our sequences, is to pre-cluster the sequences using the
<code class="highlighter-rouge">pre.cluster</code> command, allowing for up to 2 differences between sequences. This command will split the
sequences by group and then sort them by abundance and go from most abundant to least and identify
sequences that differ no more than 2 nucleotides from on another. If this is the case, then they get
merged. We generally recommend allowing 1 difference for every 100 basepairs of sequence:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-perform-preliminary-clustering-of-sequences"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Perform preliminary clustering of sequences</h3>

  <ul>
    <li><strong>Pre.cluster</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” to the fasta output from the last Unique.seqs run</li>
        <li>“name file or count table” to the count table from the last Unique.seqs</li>
        <li>“diffs” to 2</li>
      </ul>
    </li>
  </ul>

  <blockquote class="question">
    <h3 id="-question-4"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

    <p>How many unique sequences are we left with after this clustering of highly similar sequences?</p>
    <details>
  <summary> Click to view answer</summary>
  5720. This is the number of lines in the fasta output
</details>
  </blockquote>
</blockquote>

<h3 id="chimera-removal">Chimera Removal</h3>
<p>At this point we have removed as much sequencing error as we can, and it is time to turn our attention to
removing sequencing artefacts known as chimeras.</p>

<blockquote class="tip">
  <h3 id="-background-chimeras"><i class="fa fa-lightbulb-o" aria-hidden="true"></i> Background: Chimeras</h3>
  <p><img src="../../images/chimeras.jpg" alt="Chemirec sequence" />
(slide credit: <a href="http://slideplayer.com/slide/4559004/">http://slideplayer.com/slide/4559004/ </a>)</p>
</blockquote>

<p>We’ll do this chimera removal using the <code class="highlighter-rouge">VSEARCH</code> algorithm that is called within Mothur, using the
<code class="highlighter-rouge">chimera.vsearch</code> command. This command will split the data by sample and check for chimeras.</p>

<p>Our preferred way of doing this is to use the abundant sequences as our reference. In addition, if a sequence
is flagged as chimeric in one sample, the default (<code class="highlighter-rouge">dereplicate=No</code>) is to remove it from all samples. Our
experience suggests that this is a bit aggressive since we’ve seen rare sequences get flagged as chimeric
when they’re the most abundant sequence in another sample. This is how we do it:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-remove-chimeric-sequences"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Remove chimeric sequences</h3>

  <ul>
    <li><strong>Chimera.vsearch</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” to the fasta output from Pre.cluster</li>
        <li>“Select Reference Template from” to <code class="highlighter-rouge">Self</code></li>
        <li>“count” to the count table from the last Pre.cluster</li>
        <li>“dereplicate” to Yes</li>
      </ul>
    </li>
  </ul>

  <p>Running chimera.vsearch with the count file will remove the chimeric sequences from the count table, but we
still need to remove those sequences from the fasta file as well. We do this using remove.seqs:</p>

  <ul>
    <li><strong>Remove.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“accnos” to the vsearch.accnos file from Chimera.vsearch</li>
        <li>“fasta” to the fasta output from Pre.cluster</li>
        <li>“count” to the count table from Chimera.vsearch</li>
      </ul>
    </li>
  </ul>

  <blockquote class="question">
    <h3 id="-question-5"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

    <p>How many sequences were flagged as chimeric? what is the percentage? (Hint: summary.seqs)</p>
    <details>
  <summary> Click to view answer</summary>
  If we run summary.seqs on the resulting fasta file and count table, we see that we went from 128,655
  sequences down to 118,091 sequences in this step, for a reduction of 8.2%. This is a reasonable number of
  sequences to be flagged as chimeric.
</details>
  </blockquote>
</blockquote>

<h3 id="removal-of-non-bacterial-sequences">Removal of non-bacterial sequences</h3>

<p>As a final quality control step, we need to see if there are any “undesirables” in our dataset. Sometimes when
we pick a primer set they will amplify other stuff that survives to this point in the pipeline, such as
18S rRNA gene fragments or 16S rRNA from Archaea, chloroplasts, and mitochondria. There’s also just the
random stuff that we want to get rid of.</p>

<p>Now you may say, “But wait I want that stuff”. Fine. But, the primers we use, are only supposed to amplify
members of the Bacteria and if they’re hitting Eukaryota or Archaea, then it is a mistake. Also, realize
that chloroplasts and mitochondria have no functional role in a microbial community.</p>

<p>Let’s go ahead and classify those sequences using the Bayesian classifier with the <code class="highlighter-rouge">classify.seqs</code> command:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-remove-undesired-sequences"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Remove undesired sequences</h3>

  <ul>
    <li><strong>Classify.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” to the fasta output from Remove.seqs</li>
        <li>“reference” to <code class="highlighter-rouge">trainset9032012.pds.fasta</code> from your history</li>
        <li>“taxonomy” to <code class="highlighter-rouge">trainset9032012.pds.tax</code> from your history</li>
        <li>“count” to the count table file from Remove.seqs</li>
      </ul>
    </li>
  </ul>

  <p>Have a look at the taxonomy output. You will see that every read now has a classification.</p>

  <p>Now that everything is classified we want to remove our undesirables. We do this with the remove.lineage
command:</p>

  <ul>
    <li><strong>Remove.lineage</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“taxonomy” to the taxonomy output from Classify.seqs</li>
        <li>“taxon” to <code class="highlighter-rouge">Chloroplast-Mitochondria-unknown-Archaea-Eukaryota</code> in the text box under <em>Manually
select taxons for filtering</em></li>
        <li>“fasta” to the fasta output from Remove.seqs</li>
        <li>“count” to the count table from Remove.seqs</li>
      </ul>
    </li>
  </ul>

  <blockquote class="question">
    <h3 id="-questions"><i class="fa fa-question-circle" aria-hidden="true"></i> Questions</h3>

    <ol>
      <li>How many unique (representative) sequences were removed in this step?</li>
      <li>
        <p>How many sequences in total?</p>

        <details>
  <summary> Click to view answer</summary><br />
  20 representative sequences were removed. <br />
  The fasta file output from Remove.seqs had 2281 sequences while the fasta output from Remove.lineages
  contained 2261 sequences.
  <br /><br />
  162 total sequences were removed. <br />
  If you run summary.seqs with the count table, you will see that we now have 2261 unique sequences
  representing a total of 117,929 total sequences (down from 118,091 before). This means 162 of our
  sequences were in represented by these 20 representative sequences.
</details>
      </li>
    </ol>
  </blockquote>
</blockquote>

<p>Also of note is that <em>unknown</em> only pops up as a classification if the classifier cannot classify your
sequence to one of the domains.</p>

<p>At this point we have curated our data as far as possible and we’re ready to see what our error rate is.</p>

<h2 id="assessing-error-rates-based-on-our-mock-community">Assessing error rates based on our mock community</h2>

<p>Measuring the error rate of your sequences is something you can only do if you have co-sequenced a mock
community, that is, a sample of which you know the exact composition. This is something we include for
every 95 samples we sequence. You should too because it will help you gauge your error rates and allow
you to see how well your curation is going, and whether something is wrong with your sequencing setup.</p>

<blockquote class="comment">
  <h3 id="-definition"><i class="fa fa-commenting-o" aria-hidden="true"></i> Definition</h3>

  <p><strong>Mock community:</strong> A defined mixture of microbial cells and/or viruses or nucleic acid molecules created
<em>in vitro</em> to simulate the composition of a microbiome sample or the nucleic acid isolated therefrom.</p>

</blockquote>

<p>Our mock community is composed of genomic DNA from 21 bacterial strains. So in a perfect world, this is
exactly what we would expect the analysis to produce as a result.</p>

<p>First, let’s extract the sequences belonging to our mock samples from our data:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-extract-mock-sample-from-our-dataset"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: extract mock sample from our dataset</h3>

  <ol>
    <li><strong>Get.groups</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“group file or count table” to the count table from Remove.lineage</li>
        <li>“groups” to <code class="highlighter-rouge">Mock</code></li>
        <li>“fasta” to fasta output from Remove.lineage</li>
        <li>“output logfile?” to <code class="highlighter-rouge">yes</code></li>
      </ul>
    </li>
  </ol>

</blockquote>

<p>In the log file we see the following:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Selected 58 sequences from your fasta file.
Selected 4046 sequences from your count file
</code></pre>
</div>

<p>This tells us that we had 58 unique sequences and a total of 4,046 total sequences in our Mock sample. We
can now use the <code class="highlighter-rouge">seq.error</code> command to measure the error rates based on our mock reference. Here we align
the reads from our mock sample back to their known sequences, to see how many fail to match.</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-assess-error-rates-based-on-a-mock-community"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Assess error rates based on a mock community</h3>
  <ul>
    <li><strong>Seq.error</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” to the fasta from Get.groups</li>
        <li>“reference” to <code class="highlighter-rouge">HMP_MOCK.v35.fasta</code> file from your history</li>
        <li>“count” to the count table from Get.groups</li>
        <li>“output log?” to <code class="highlighter-rouge">yes</code></li>
      </ul>
    </li>
  </ul>

</blockquote>

<p>In the log file we see something like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Overall error rate:    6.5108e-05
Errors    Sequences
0    3998
1    3
2    0
3    2
4    1
[..]
</code></pre>
</div>

<p>That rocks, eh? Our error rate is 0.0065%!</p>

<h3 id="cluster-mock-sequences-into-otus">Cluster mock sequences into OTUs</h3>

<p>We can now cluster the mock sequences into OTUs to see how many spurious OTUs we have:</p>

<blockquote class="tip">
  <h3 id="-background-operational-taxonomic-units-otus"><i class="fa fa-lightbulb-o" aria-hidden="true"></i> Background: Operational Taxonomic Units (OTUs)</h3>

  <p>In 16S metagenomics approaches, OTUs are clusters of similar sequence variants of the 16S rDNA marker gene
sequence. Each of these clusters is intended to represent a taxonomic unit of a bacteria species or genus
depending on the sequence similarity threshold. Typically, OTU cluster are defined by a 97% identity
threshold of the 16S gene sequence variants at species level. 98% or 99% identity is suggested for strain
separation.</p>

  <p><img src="../../images/OTU_graph.png" alt="OTU graph" /></p>

  <p>(Image credit: Danzeisen et al. 2013, 10.7717/peerj.237)</p>
</blockquote>

<blockquote class="hands_on">
  <h3 id="-hands-on-cluster-mock-sequences-into-otus"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Cluster mock sequences into OTUs</h3>

  <p>First we calculate the pairwise distances between our sequences</p>

  <ul>
    <li><strong>Dist.seqs</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“fasta” to the fasta from Get.groups</li>
        <li>“cutoff” to <code class="highlighter-rouge">0.20</code></li>
      </ul>
    </li>
  </ul>

  <p>Next we group sequences into OTUs</p>

  <ul>
    <li><strong>Cluster</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“column” to the dist output from Dist.seqs</li>
        <li>“count” to the count table from Get.groups</li>
      </ul>
    </li>
  </ul>

  <p>Now we make a <em>shared</em> file that summarizes all our data into one handy table</p>

  <ul>
    <li><strong>Make.shared</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“list” to the OTU list from Cluster</li>
        <li>“count” to the count table from Get.groups</li>
        <li>“label” to <code class="highlighter-rouge">0.03</code> (this indicates we are interested in the clustering at a 97% identity threshold)</li>
      </ul>
    </li>
  </ul>

  <p>And now we generate intra-sample rarefaction curves</p>

  <ul>
    <li><strong>Rarefaction.single</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“shared” to the shared file from Make.shared</li>
      </ul>
    </li>
  </ul>

  <blockquote class="question">
    <h3 id="-question-6"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

    <p>How many OTUs were identified in our mock community?</p>
    <details>
  <summary> Click to view answer</summary>
  34. <br />
  Open the shared file or OTU list and look at the header line. You will see a column for each OTU
 </details>
  </blockquote>
</blockquote>

<p>Open the rarefaction output (dataset named <code class="highlighter-rouge">sobs</code> inside the <code class="highlighter-rouge">rarefaction curves</code> output collection).
You’ll see that for 4060 sequences, we’d have 34 OTUs from the Mock community. This number of course
includes some stealthy chimeras that escaped our detection methods. If we used 3000 sequences, we would
have about 31 OTUs. In a perfect world with no chimeras and no sequencing errors, we’d have 20 OTUs.
This is not a perfect world. But this is pretty darn good!</p>

<blockquote class="tip">
  <h3 id="-background-rarefaction"><i class="fa fa-lightbulb-o" aria-hidden="true"></i> Background: Rarefaction</h3>

  <p>To estimate the fraction of species sequenced, rarefaction curves are typically used. A rarefaction curve
plots the number of species as a function of the number of individuals sampled. The curve usually begins
with a steep slope, which at some point begins to flatten as fewer species are being discovered per sample:
the gentler the slope, the less contribution of the sampling to the total number of operational taxonomic
units or OTUs.</p>

  <p><img src="../../images/rarefaction.png" alt="Rarefaction curves" /></p>

  <p>Green, most or all species have been sampled; blue, this habitat has not been exhaustively sampled; red,
species rich habitat, only a small fraction has been sampled.</p>

  <p>(<em>A Primer on Metagenomics</em>, Wooley et al. 2010, https://dx.doi.org/10.1371/journal.pcbi.1000667)</p>
</blockquote>

<p>Now that we have assessed our error rates we are ready for some real analysis.</p>

<h2 id="preparing-for-analysis">Preparing for analysis</h2>

<h3 id="removing-mock-sample">Removing Mock sample</h3>
<p>We’re almost to the point where you can have some fun with your data (I’m already having fun, aren’t you?).
Next, we would assign sequences to OTUs, but first, we should remove the Mock sample from our dataset, it has
served its purpose by allowing us to estimate our error rate, but in subsequent steps we only want to use
our real samples.</p>

<p>using
the <code class="highlighter-rouge">remove.groups</code> command:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-remove-mock-community-from-our-dataset"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Remove Mock community from our dataset</h3>

  <ul>
    <li><strong>Remove.groups</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Select input type” to <code class="highlighter-rouge">fasta , name, taxonomy, or list with a group file or count table</code></li>
        <li>“count table”, “fasta”, and “taxonomy” to the respective outputs from Remove.lineage</li>
        <li>“groups” to <code class="highlighter-rouge">Mock</code></li>
      </ul>
    </li>
  </ul>
</blockquote>

<h3 id="clustering-sequences-into-otus">Clustering sequences into OTUs</h3>

<p>Now, we have a couple of options for clustering sequences into OTUs. For a small dataset like this, we could
do the traditional approach using <code class="highlighter-rouge">dist.seqs</code> and <code class="highlighter-rouge">cluster</code> as we did with the Mock sample.</p>

<p>The alternative is to use the <code class="highlighter-rouge">cluster.split</code> command. In this approach, we use the taxonomic information to
split the sequences into bins and then cluster within each bin. The Schloss lab have published results
showing that if you split at the level of Order or Family, and cluster to a 0.03 cutoff, you’ll get just as
good of clustering as you would with the “traditional” approach.</p>

<p>The advantage of the <code class="highlighter-rouge">cluster.split</code> approach is that it should be faster, use less memory, and can be run on
multiple processors. In an ideal world we would prefer the traditional route because “Trad is rad”, but we
also think that kind of humor is funny…. In this command we use <code class="highlighter-rouge">taxlevel=4</code>, which corresponds to the level
of <em>Order</em>. This is the approach that we  generally use in the Schloss lab.</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-cluster-our-data-into-otus"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Cluster our data into OTUs</h3>

  <ul>
    <li><strong>Cluster.split</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Split by” to <code class="highlighter-rouge">Classification using fasta</code></li>
        <li>“fasta” to the fasta output from Remove.groups</li>
        <li>“taxonomy” to the taxonomy output from Remove.groups</li>
        <li>“name file or count table” to the count table output from Remove.groups</li>
        <li>“taxlevel” to <code class="highlighter-rouge">4</code></li>
        <li>“cutoff” to <code class="highlighter-rouge">0.03</code></li>
      </ul>
    </li>
  </ul>

  <p>Next we want to know how many sequences are in each OTU from each group and we can do this using the
<code class="highlighter-rouge">Make.shared</code> command. Here we tell Mothur that we’re really only interested in the 0.03 cutoff level:</p>

  <ul>
    <li><strong>Make.shared</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Select input type” to <code class="highlighter-rouge">OTU list</code></li>
        <li>“list” to list output from Cluster.split</li>
        <li>“count” to the count table from Remove.groups</li>
        <li>“label” to <code class="highlighter-rouge">0.03</code></li>
      </ul>
    </li>
  </ul>

  <p>We probably also want to know the taxonomy for each of our OTUs. We can get the consensus taxonomy for each
OTU using the <code class="highlighter-rouge">Classify.otu</code> command:</p>

  <ul>
    <li><strong>Classify.otu</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“list” to output from Cluster.split</li>
        <li>“count” to the count table from Remove.groups</li>
        <li>“taxonomy” to the taxonomy output from Remove.groups</li>
        <li>“label” to <code class="highlighter-rouge">0.03</code></li>
      </ul>
    </li>
  </ul>

</blockquote>

<p>Opening the taxonomy output for level 0.03 shows a file structured like the following:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>OTU       Size    Taxonomy
..
Otu0008	5260	Bacteria(100);"Bacteroidetes"(100);"Bacteroidia"(100);"Bacteroidales"(100);"Rikenellaceae"(100);Alistipes(100);
Otu0009	3613	Bacteria(100);"Bacteroidetes"(100);"Bacteroidia"(100);"Bacteroidales"(100);"Porphyromonadaceae"(100);"Porphyromonadaceae"_unclassified(100);
Otu0010	3058	Bacteria(100);Firmicutes(100);Bacilli(100);Lactobacillales(100);Lactobacillaceae(100);Lactobacillus(100);
Otu0011	2958	Bacteria(100);"Bacteroidetes"(100);"Bacteroidia"(100);"Bacteroidales"(100);"Porphyromonadaceae"(100);"Porphyromonadaceae"_unclassified(100);
Otu0012	2134	Bacteria(100);"Bacteroidetes"(100);"Bacteroidia"(100);"Bacteroidales"(100);"Porphyromonadaceae"(100);"Porphyromonadaceae"_unclassified(100);
Otu0013	1856	Bacteria(100);Firmicutes(100);Bacilli(100);Lactobacillales(100);Lactobacillaceae(100);Lactobacillus(100);
..
</code></pre>
</div>

<p>This file tells you that Otu008 was observed 5260 times in your samples and that all of the
sequences (100%) were classified as being members of the Alistipes.</p>

<blockquote class="question">
  <h3 id="-question-7"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

  <p>Which samples contained sequences belonging to an OTU classified as Staphylococcus?</p>

  <details><summary>Hint</summary>
Examine the tax.summary file.
 </details>

  <details><summary>Answer</summary>
Samples F3D141, F3D142,  F3D144, F3D145, F3D2. This answer can be found by
examining the tax.summary output and finding the columns with nonzero
values for the line of Staphylococcus
</details>
</blockquote>

<p>In this tutorial we will continue with this otu-based approach, for the phylotype and phylogenic
approaches, please refer to the <a href="https://www.mothur.org/wiki/MiSeq_SOP">Mothur wiki page</a>.</p>

<h1 id="otu-based-analysis">OTU-based Analysis</h1>

<p>Let’s do something more interesting and actually analyze our data. We’ll focus on the OTU-based dataset. The
phylotype-based analysis is essentially the same. Also, remember that our initial question had to do with the
stability and change in community structure in these samples when comparing early and late samples.</p>

<p>Keep in mind that the group names have either a F or M (sex of animal) followed by a number (number of
animal) followed by a D and a three digit number (number of days post weaning).</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-subsampling"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Subsampling</h3>

  <p>What we now want to do is see how many sequences we have in each sample. We’ll do this with the
<code class="highlighter-rouge">Count.groups</code> command:</p>

  <ul>
    <li><strong>Count.groups</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“shared” to the shared file from Make.shared</li>
      </ul>
    </li>
  </ul>

  <p>Take a look at the output. We see that our smallest sample had 2389 sequences in it. That is a reasonable
number. Despite what some say, subsampling and rarefying your data is an important thing to do.</p>

  <p>We’ll generate a subsampled file for our analyses with the <code class="highlighter-rouge">Sub.sample</code> command:</p>

  <ul>
    <li><strong>Sub.sample</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Select type of data to subsample” to <code class="highlighter-rouge">OTU Shared</code></li>
        <li>“shared” to output from Make.shared</li>
        <li>“size” to <code class="highlighter-rouge">2389</code></li>
      </ul>
    </li>
  </ul>

  <blockquote class="question">
    <h3 id="-question-8"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

    <p>What would you exect the result of <code class="highlighter-rouge">count.groups</code> on this new shared output collection to be? Check if you are correct.</p>
    <details>
  <summary> Click to view answer</summary>
  all groups (samples) should now have 2440 sequences. Run count.groups again on the shared output collection by the sub.sample
  tool to confirm that this is indeed what happened.
 </details>
  </blockquote>

  <p><strong>Note:</strong> since subsampling is a stochastic process, your results from any tools using this subsampled data
will deviate from the ones presented here.</p>
</blockquote>

<h2 id="calculate-species-diversity">Calculate Species Diversity</h2>

<p>Diversity indices provide valuable mathematical tools to describe the ecological complexity of a single sample
(<em>alpha diversity</em>) or to detect species differences between samples (<em>beta diversity</em>). However, diversity
is not a determined physical quantity for which a consensus definition and unit of measure have been established,
and several diversity indices are currently available [Finotello et al. 2016].</p>

<h3 id="alpha-diversity">Alpha diversity</h3>

<p>Let’s start our analysis by analyzing the alpha diversity of the samples. First we will generate rarefaction
curves describing the number of OTUs observed as a function of sampling effort. We’ll do this with the
<code class="highlighter-rouge">Rarefaction.single</code> command:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-calculate-rarefaction"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Calculate Rarefaction</h3>
  <ul>
    <li><strong>Rarefaction.single</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“shared” to shared file from Make.shared</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Note that we used the default diversity measure here (<em>sobs</em>; observed species richness), but there are many
more options available under the <em>calc</em> parameter. The mothur wiki describes some of these calculators
<a href="https://mothur.org/wiki/Calculators">here</a>.</p>

<p>Examine the rarefaction curve output.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>numsampled    0.03-F3D0    lci-F3D0    hci-F3D0    0.03-F3D1   ...
1              1.0000       1.0000      1.0000      1.0000
100           41.6560      35.0000     48.0000     45.0560
200           59.0330      51.0000     67.0000     61.5740
300           70.5640      62.0000     79.0000     71.4700
400           78.8320      71.0000     87.0000     78.4730
500           85.3650      77.0000     94.0000     83.9990
...
</code></pre>
</div>

<p>This file displays the number of OTUs identified per amount of sequences used (numsampled). What we would like
to see is the number of additional OTUs identified when adding more sequences reaching a plateau. Then we know
we have covered our full diversity. This information would be easier to interpret in the form of a graph.
Let’s plot the rarefaction curve for a couple of our sequences:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-plot-rarefaction"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Plot Rarefaction</h3>
  <!-- the following tool is because plotting tool will not detect columns in files inside collections yet -->
  <p>First let’s make our life a little bit easier. As we only have one dataset in our collection anyways, we can
collapse it into a single file.</p>

  <ul>
    <li><strong>Collapse Collection</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Collection of files to collapse to a single dataset” to the rarefaction curve collection</li>
      </ul>
    </li>
  </ul>

  <p>Now we are ready to plot our rarefaction curves:</p>

  <ul>
    <li><strong>Plotting tool</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Plot Title” to <code class="highlighter-rouge">Rarefaction</code></li>
        <li>“Label for x axis” to <code class="highlighter-rouge">Number of Sequences</code></li>
        <li>“Label for y axis” to <code class="highlighter-rouge">Number of OTUs</code></li>
        <li>“Output File Type” to <code class="highlighter-rouge">PNG</code></li>
        <li>Click on Insert Series,
          <ul>
            <li>“Dataset” to the collapsed rarefaction curve collection</li>
            <li>Set <strong>Header in first line?</strong> to <code class="highlighter-rouge">Yes</code></li>
            <li>“Column for x axis” to <code class="highlighter-rouge">Column 1</code></li>
            <li>“Column for y-axis” to <code class="highlighter-rouge">Column 2</code> and <code class="highlighter-rouge">Column 5</code> and every third column until the end (we are
skipping the low confidence and high confidence interval columns)</li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>

</blockquote>

<p>From the resulting image we can see that the rarefaction curves for all samples have started to level
off so we are confident we cover a large part of our sample diversity.</p>

<p><img src="../../images/rarefaction_curves.png" alt="Rarefaction curves" /></p>

<p>Alas, rarefaction is not a measure of richness, but a measure of diversity. If you consider two communities
with the same richness, but different evenness then after sampling a large number of individuals their
rarefaction curves will asymptote to the same value. Since they have different evennesses the shapes of
the curves will differ. Therefore, selecting a number of individuals to cutoff the rarefaction curve isn’t
allowing a researcher to compare samples based on richness, but their diversity.</p>

<p>Finally, let’s get a table containing the number of sequences, the sample coverage, the number of observed
OTUs, and the Inverse Simpson diversity estimate using the <code class="highlighter-rouge">Summary.single</code> command. To standardize everything,
let’s randomly select 2440 sequences from each sample 1000 times and calculate the average:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-summarysingle"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Summary.single</h3>

  <ul>
    <li><strong>Summary.single</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“share” to shared file from Make.shared</li>
        <li>“calc” to <code class="highlighter-rouge">nseqs,coverage,sobs,invsimpson</code></li>
        <li>“size” to 2389</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>The data will be outputted to a table called the <em>summary file</em>:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>label   group   sobs          coverage    invsimpson   invsimpson_lci   invsimpson_hci  nseqs
0.03    F3D0    167.000000    0.994697    25.686387    24.648040        26.816067       6223.000000
0.03    F3D1    145.000000    0.994030    34.598470    33.062155        36.284520       4690.000000
0.03    F3D141  154.000000    0.991060    19.571632    18.839994        20.362390       4698.000000
0.03    F3D142  141.000000    0.978367    17.029921    16.196090        17.954269       2450.000000
0.03    F3D143  135.000000    0.980738    18.643635    17.593785        19.826728       2440.000000
0.03    F3D144  161.000000    0.980841    15.296728    14.669208        15.980336       3497.000000
0.03    F3D145  169.000000    0.991222    14.927279    14.494740        15.386427       5582.000000
0.03    F3D146  161.000000    0.989167    22.266620    21.201364        23.444586       3877.000000
0.03    F3D147  210.000000    0.995645    15.894802    15.535594        16.271013       12628.000000
0.03    F3D148  176.000000    0.995725    17.788205    17.303206        18.301177       9590.000000
0.03    F3D149  194.000000    0.994957    21.841083    21.280343        22.432174       10114.000000
0.03    F3D150  164.000000    0.989446    23.553161    22.462533        24.755101       4169.000000
0.03    F3D2    179.000000    0.998162    15.186238    14.703161        15.702137       15774.000000
0.03    F3D3    127.000000    0.994167    14.730640    14.180453        15.325243       5315.000000
0.03    F3D5    138.000000    0.990523    29.415378    28.004777        30.975621       3482.000000
0.03    F3D6    155.000000    0.995339    17.732145    17.056822        18.463148       6437.000000
0.03    F3D7    126.000000    0.991916    13.343631    12.831289        13.898588       4082.000000
0.03    F3D8    158.000000    0.992536    23.063894    21.843396        24.428855       4287.000000
0.03    F3D9    162.000000    0.994803    24.120541    23.105499        25.228865       5773.000000
</code></pre>
</div>

<p>Interestingly, the sample coverages were all above 97%, indicating that we did a pretty good job of sampling
the communities. Plotting the richness or diversity of the samples would show that there was little difference
between the different animals or between the early and late time points. You could follow this up with a
repeated-measures ANOVA and find that there was no significant difference based on sex or early vs. late.</p>

<h3 id="beta-diversity">Beta diversity</h3>

<p>Beta diversity is a measure of the similarity of the membership and structure found between <em>different</em> samples.
The default calculator in the following section is <em>thetaYC</em>, which is the <a href="http://csyue.nccu.edu.tw/2005communicationindex.pdf">Yue &amp; Clayton theta similarity
coefficient</a></p>

<blockquote class="hands_on">
  <h3 id="-hands-on-beta-diversity"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Beta diversity</h3>

  <p>Let’s calculate . We’ll do this
with the <code class="highlighter-rouge">Dist.shared</code> command that will allow us to rarefy our data to a common number of sequences.</p>

  <ul>
    <li><strong>Dist.shared</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“shared” to the shared file from Make.shared</li>
        <li>“calc” to thetayc,jclass</li>
        <li>“subsample” to 2389</li>
      </ul>
    </li>
  </ul>

  <p>Let’s visualize our data in a Heatmap</p>

  <ul>
    <li><strong>Heatmap.sim</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Generate Heatmap for” to <code class="highlighter-rouge">phylip</code></li>
        <li>“phylip” to output by Dist.shared (this is a collection input)</li>
      </ul>
    </li>
  </ul>

  <!-- TODO: way to view the SVGs inside Galaxy? -->
</blockquote>

<p>Look at some of the resulting heatmaps (you may have to download the SVG images first). In all of these
heatmaps the red colors indicate communities that are more similar than those with black colors.</p>

<p>For example this is the heatmap for the <code class="highlighter-rouge">thetayc</code> calculator (output <code class="highlighter-rouge">thetayc.0.03.lt.ave</code>):</p>

<p><img src="../../images/heatmap.sim_thetayc.png" alt="Heatmap for the thetayc calculator" /></p>

<p>and the jclass calulator (output <code class="highlighter-rouge">jclass.0.03.lt.ave</code>):</p>

<p><img src="../../images/heatmap.sim_jclass.png" alt="Heatmap for the jclass calculator" /></p>

<p>When generating Venn diagrams we are limited by the number of samples that we can analyze simultaneously.
Let’s take a look at the Venn diagrams for the first 4 time points of female 3 using the <code class="highlighter-rouge">venn</code> command:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-venn-diagram"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Venn diagram</h3>

  <!-- need to collapse collection again for group select to work -->
  <p>First we collapse our collection again</p>

  <ul>
    <li><strong>Collapse Collection</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Collection” to Subsample.shared output collection from Sub.sample step</li>
      </ul>
    </li>
  </ul>

  <p>After the tool has finished, rename the output to <code class="highlighter-rouge">Subsample.shared</code> to make it easier to recognize in
further analysis</p>

  <ul>
    <li><strong>Venn</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>Set <code class="highlighter-rouge">OTU Shared</code> to Subsample.shared file from previous step</li>
        <li>Set <code class="highlighter-rouge">groups</code> to <code class="highlighter-rouge">F3D0,F3D1,F3D2,F3D3</code></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>This generates a 4-way Venn diagram and a table listing the shared OTUs.</p>

<p><img src="../../images/venn.png" alt="Venn diagram and table with shared OTUs" /></p>

<p>This shows that there were a total of 180 OTUs observed between the 4 time points. Only 76 of those OTUs were
shared by all four time points. We could look deeper at the shared file to see whether those OTUs were
umerically rare or just had a low incidence.</p>

<p>Next, let’s generate a dendrogram to describe the similarity of the samples to each other. We will generate a
dendrogram using the jclass and thetayc calculators within the <code class="highlighter-rouge">tree.shared</code> command:</p>

<blockquote class="hands_on">
  <h3 id="-tree"><i class="fa fa-pencil" aria-hidden="true"></i> Tree</h3>

  <ol>
    <li><strong>Tree.shared</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Select input format” to Phylip Distance Matrix</li>
        <li>“phylip” to dist files from Dist.shared (collection)</li>
      </ul>
    </li>
    <li><strong>Newick display</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Newick file” to output from Tree.shared (collection)</li>
      </ul>
    </li>
  </ol>
</blockquote>

<p>Inspection of the the tree shows that the early and late communities cluster with themselves to the exclusion
of the others.</p>

<p><code class="highlighter-rouge">thetayc.0.03.lt.ave</code>:</p>

<p><img src="../../images/tree.thetayc.png" alt="Thetayc tree" /></p>

<p><code class="highlighter-rouge">jclass.0.03.lt.ave</code>:</p>

<p><img src="../../images/tree.jclass.png" alt="Jclass tree" /></p>

<h1 id="visualisations">Visualisations</h1>

<p>Mothur does not have a lot of visualization tools built in, but external tools may be used for this. For
instance we can convert our shared file to the more widely used <code class="highlighter-rouge">biom</code> format and view it in a platform like
<a href="http://www.phinch.org/">Phinch</a>.</p>

<h2 id="phinch">Phinch</h2>

<blockquote class="hands_on">
  <h3 id="-hands-on-phinch"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Phinch</h3>

  <ul>
    <li><strong>Make.biom</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“shared” to Subsample.shared</li>
        <li>“constaxonomy” to taxonomy output from Classify.otu (collection)</li>
        <li>“metadata” to <code class="highlighter-rouge">mouse.dpw.metadata</code></li>
      </ul>
    </li>
  </ul>

  <p>The Galaxy project runs an instance of Phinch, and if you look at the output biom file, you will see a link
to view the file at Phinch:</p>

  <p><img src="../../../../shared/images/viewatphinch.png" alt="Icon to view at Phinch" /></p>

  <p>Clicking on this link will lead you to the Phinch website, which will automatically load in your file, and
where you can several interactive visualisations:</p>

  <p><img src="../../../../shared/images/phinch_overviewpage.png" alt="Phinch overview" /></p>

  <blockquote class="comment">
    <h3 id="-comment"><i class="fa fa-commenting-o" aria-hidden="true"></i> Comment</h3>

    <p>If this link is not present on your Galaxy, you can download the generated BIOM file and upload directly to Phinch server at <a href="http://phinch.org">http://phinch.org</a>.</p>
  </blockquote>
</blockquote>

<h2 id="krona">Krona</h2>

<p>A second tool we can use to visualize our data, is <a href="">Krona</a></p>

<blockquote class="hands_on">
  <h3 id="-hands-on-krona"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Krona</h3>

  <p>First we convert our mothur taxonomy file to a format compatible with Krona</p>

  <ul>
    <li><strong>Taxonomy-to-Krona</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Taxonomy file” to the taxonomy output from Classify.otu (collection)</li>
      </ul>
    </li>
    <li><strong>Krona pie chart</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“Type of input” to <code class="highlighter-rouge">Tabular</code></li>
        <li>“Input file” to taxonomy output from Classify.otu (collection)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>The resulting file is an HTML file containing an interactive visualization. For instance try double-clicking the
innermost ring labeled “Bacteria”</p>

<p><img src="../../images/krona.png" alt="Krona" /></p>

<blockquote class="question">
  <h3 id="-question-9"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

  <p>What percentage of your sample was labelled <code class="highlighter-rouge">Lactobacillus</code>?</p>

  <details>
  <summary> Click to view answer</summary>
  Explore the Krona plot, double click on Firmicutes, here you should see Lactobacillus
  clearly (16% in our case), click on this segment and the right-hand side will show you the percentages at
  any point in the hierarchy (here 5% of all)

 <img src="../../images/krona_lacto.png" alt="image showing view with Lactobacillus highlighted" />
</details>
</blockquote>

<p>Well done! you have completed the basics of the mothur SOP. Below are some more exercises for those who wish to
go into more details about statistical significance testing and population-level analysis.</p>

<h1 id="extra-credit">Extra Credit</h1>

<h2 id="determine-statistical-significance-of-clusterings">Determine statistical significance of clusterings</h2>

<p>We can perform a test to determine whether the clustering within the tree is statistically significant or not
using by choosing from the <code class="highlighter-rouge">parsimony</code>, <code class="highlighter-rouge">unifrac.unweighted</code>, or <code class="highlighter-rouge">unifrac.weighted</code> commands. To run these we
will first need to create a design file that indicates which treatment each sample belongs to.</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-obtain-design-file"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Obtain design file</h3>

  <ul>
    <li>Find the file <code class="highlighter-rouge">mouse.time.design</code> in your history (you imported this file at the start of this tutorial)</li>
    <li>Make sure the datatype is set to <code class="highlighter-rouge">mothur.design</code>.</li>
  </ul>

  <blockquote class="tip">
    <h3 id="-changing-datatype-of-a-datasets"><i class="fa fa-lightbulb-o" aria-hidden="true"></i> Changing datatype of a datasets</h3>
    <ul>
      <li>Click on the <strong>pencil icon</strong> of the dataset</li>
      <li>Click on the <strong>Datatypes</strong> tab</li>
      <li>Select the new datatype from dropdown menu</li>
      <li>Click <strong>Save</strong></li>
    </ul>
  </blockquote>
</blockquote>

<p>The design file look something like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>group    time
F3D0     Early
F3D1     Early
F3D141   Late
F3D142   Late
F3D143   Late
F3D144   Late
F3D145   Late
F3D146   Late
F3D147   Late
F3D148   Late
F3D149   Late
F3D150   Late
F3D2     Early
F3D3     Early
F3D5     Early
F3D6     Early
F3D7     Early
F3D8     Early
F3D9     Early
</code></pre>
</div>

<p>Using the <code class="highlighter-rouge">parsimony</code> command let’s look at the pairwise comparisons. Specifically, let’s focus on the
early vs. late comparisons for each mouse:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-compare-early-vs-late"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Compare Early-vs-Late</h3>
  <ul>
    <li><strong>Parsimony</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“tree” to the <code class="highlighter-rouge">tre</code> output from Tree.Shared (collection)</li>
        <li>“group” to the design file described above</li>
        <li>“output logfile?” to <code class="highlighter-rouge">yes</code></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>In the logfile for <code class="highlighter-rouge">thetayc.0.03.lt.ave</code> we see</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Tree#   Groups      ParsScore   ParsSig
1       Early-Late  1           &lt;0.001
</code></pre>
</div>

<p>There was clearly a significant difference between the clustering of the early and late time points.
Recall that this method ignores the branch length.</p>

<p>The two distance matrices that we generated earlier (i.e. <code class="highlighter-rouge">jclass.0.03.lt.ave.dist</code> and
    <code class="highlighter-rouge">thetayc.0.03.lt.ave.dist</code>) can then be visualized using the pcoa or nmds plots.</p>

<p>Principal Coordinates (PCoA) uses an eigenvector-based approach to represent multidimensional
data in as few dimensions as possible. Our data is highly dimensional (~9 dimensions).</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-pcoa"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: PCoA</h3>

  <ul>
    <li><strong>Pcoa</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“phylip” to dist files from Dist.shared (collection)</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>The loadings files will tell you what fraction of the total variance in the data are represented
by each of the axes. For instance the loading file for <code class="highlighter-rouge">thetayc.0.03.lt.ave</code> looks something like:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>axis  loading
1     45.354207
2     13.526582
3     11.791424
4     4.493544
5     4.012474
...
</code></pre>
</div>

<p>In this case the first and second axis represent about 45 and 14% of the variation (59% of the total)
for the thetaYC distances. The output to the logfile:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Processing...
Rsq 1 axis: 0.736369
Rsq 2 axis: 0.882025
Rsq 3 axis: 0.978093
</code></pre>
</div>

<p>indicates that the R-squared between the original distance matrix and the distance between the points in 2D
PCoA space was 0.88, but that if you add a third dimension the R-squared value increases to 0.98. All in all,
not bad.</p>

<p>Alternatively, non-metric multidimensional scaling (NMDS) tries to preserve the distance between samples using
a user defined number of dimensions. We can run our data through NMDS with 2 dimensions with the following
tool:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-nmds"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Nmds</h3>

  <ul>
    <li><strong>Nmds</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“phylip” to dist files from Dist.shared (collection)</li>
        <li>“output logfile?” to <code class="highlighter-rouge">yes</code></li>
      </ul>
    </li>
  </ul>

  <p>Opening the <code class="highlighter-rouge">stress</code> file for <code class="highlighter-rouge">thetayc.0.03.lt.ave</code> we can inspect the stress and R^2 values, which describe
the quality of the ordination. Each line in this file represents a different iteration and the configuration
obtained in the iteration with the lowest stress is reported in the <code class="highlighter-rouge">axes</code> file. In the logfile:</p>

  <div class="highlighter-rouge"><pre class="highlight"><code>Number of dimensions:           2
Lowest stress :                 0.113657
R-squared for configuration:    0.947622
</code></pre>
  </div>

  <p>We find that the lowest stress value was 0.11 with an R-squared value of 0.95; that stress level is
actually pretty good. You can test what happens with three dimensions in the following way:</p>

  <ul>
    <li><strong>Nmds</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“phylip” to dist files collection from Dist.shared</li>
        <li>“mindim” to <code class="highlighter-rouge">3</code></li>
        <li>“maxdim” to <code class="highlighter-rouge">3</code></li>
        <li>“output logfile?” to <code class="highlighter-rouge">yes</code></li>
      </ul>
    </li>
  </ul>

  <blockquote class="question">
    <h3 id="-question-10"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

    <p>What are stress and R-squared values when using 3 dimensions?</p>

    <details>
  <summary> Click to view answer</summary>
  The stress value drops to 0.05 and the R2 value goes up to 0.99 (see logfile). Not bad.
</details>
  </blockquote>
</blockquote>

<p>In general, we would like a stress value below 0.20 and a value below 0.10 is even better. Thus, we can conclude that,
NMDS is better than PCoA. We can plot the three dimensions of the NMDS data by plotting the contents of the <code class="highlighter-rouge">axes</code>
file. <!-- TODO: tool for 3D plots in Galaxy? --></p>

<p>Again, it is clear that the early and late samples cluster separately from each other. Ultimately, ordination
is a data visualization tool. We might ask if the spatial separation that we see between the early and late
plots in the NMDS plot is statistically significant. To do this we have two statistical tools at our disposal.
The first analysis of molecular variance (AMOVA), tests whether the centers of the clouds representing a group
are more separated than the variation among samples of the same treatment. This is done using the distance
matrices we created earlier and does not actually use ordination.</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-amova"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Amova</h3>

  <ul>
    <li><strong>Amova</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“phylip” to dist files from Dist.shared (collection)</li>
        <li>“design” to mouse.time.design file from your history</li>
        <li>“output logfile?” to <code class="highlighter-rouge">yes</code></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>in logfile for thetaYC we find:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Early-Late    Among       Within     Total
SS            0.628379    0.552221   1.1806
df            1           17         18
MS    0.628379    0.0324836

Fs:    19.3445
p-value: &lt;0.001*
</code></pre>
</div>

<p>Here we see from the AMOVA that the “cloud” early and late time points has a significantly different centroid
for this mouse. Thus, the observed separation in early and late samples is statistically significant. We can
also see whether the variation in the early samples is significantly different from the variation in the late
samples using the <code class="highlighter-rouge">Homova</code> command:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-homova"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Homova</h3>

  <ul>
    <li><strong>Homova</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“phylip” to dist files from Dist.shared (collection)</li>
        <li>“design” to mouse.time.design file from your history</li>
        <li>“output logfile?” to <code class="highlighter-rouge">yes</code></li>
      </ul>
    </li>
  </ul>
</blockquote>

<div class="highlighter-rouge"><pre class="highlight"><code>HOMOVA        BValue     P-value    SSwithin/(Ni-1)_values
Early-Late    7.51408    &lt;0.001*    0.0603208    0.00773943
</code></pre>
</div>

<p>We see that there is a significant difference in the variation with the early samples having a larger amount
of variation (0.061) than the late samples (0.008). This was what we found in the original study - the early
samples were less stable than the late samples.</p>

<p>Next, we might ask which OTUs are responsible for shifting the samples along the two axes. We can determine
this by measuring the correlation of the relative abundance of each OTU with the two axes in the NMDS dataset.
We do this with the <code class="highlighter-rouge">corr.axes</code> tool:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-correlation"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Correlation</h3>

  <ul>
    <li><strong>Corr.axes</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“axes” to axes output from Nmds in 3 dimension (collection)</li>
        <li>“shared” to shared output from collapse collection on Sub.sample</li>
        <li>“method” to <code class="highlighter-rouge">Spearman</code></li>
        <li>“numaxes” to <code class="highlighter-rouge">3</code></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Examining the axes output, we see the data for the first five OTUs look something like this..</p>

<div class="highlighter-rouge"><pre class="highlight"><code>OTU         axis1       p-value      axis2       p-value     axis3       p-value     length
Otu0001     0.285213    0.226258    -0.742431    0.000272    0.676613    0.001466    1.044201
Otu0002     0.283582    0.228923    -0.636524    0.003387    0.873574    0.000001    1.117458
Otu0003     0.461270    0.046828    -0.586271    0.008337    0.767610    0.000125    1.070378
Otu0004    -0.131579    0.576679    -0.240351    0.307860    0.408772    0.082266    0.492114
Otu0005    -0.315327    0.180955     0.046553    0.843432    0.097497    0.679135    0.333323
...
</code></pre>
</div>

<p>What these results show is that OTUs 1 and 2 are responsible for moving points in a negative direction along
axis 2. Recalling that we classified each OTU earlier (see taxonomy output from <code class="highlighter-rouge">Classify.otu</code>), we can see
that these first five OTUs are mainly members of the Porphyromonadaceae:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>OTU        Size   Taxonomy
Otu0001    12329   Bacteria(100);"Bacteroidetes"(100);"Bacteroidia"(100);"Bacteroidales"(100);"Porphyromonadaceae"(100);unclassified(100);
Otu0002    8912    Bacteria(100);"Bacteroidetes"(100);"Bacteroidia"(100);"Bacteroidales"(100);"Porphyromonadaceae"(100);unclassified(100);
Otu0003    7857    Bacteria(100);"Bacteroidetes"(100);"Bacteroidia"(100);"Bacteroidales"(100);"Porphyromonadaceae"(100);unclassified(100);
Otu0004    7483    Bacteria(100);"Bacteroidetes"(100);"Bacteroidia"(100);"Bacteroidales"(100);"Porphyromonadaceae"(100);Barnesiella(100);
Otu0005    7479    Bacteria(100);"Bacteroidetes"(100);"Bacteroidia"(100);"Bacteroidales"(100);"Porphyromonadaceae"(100);unclassified(100);
...
</code></pre>
</div>

<p>This helps to illustrate the power of OTUs over phylotypes since each of these OTUs is behaving differently.
These data can be plotted in what’s known as a biplot where lines radiating from the origin (axis1=0, axis2=0,
axis3=0) to the correlation values with each axis are mapped on top of the PCoA or NMDS plots.
<!-- TODO: make this plot? --></p>

<p>Later, using the metastats command, we will see another method for describing which populations are
responsible for differences seen between specific treatments.</p>

<p>An alternative approach to building a biplot would be to provide data indicating metadata about each sample.
For example, we may know the weight, height, blood pressure, etc. of the subjects in these samples. For
discussion purposes the file <code class="highlighter-rouge">mouse.dpw.metadata</code> is provided and looks something like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>group    dpw
F3D0     0
F3D1     1
F3D141   141
F3D142   142
F3D143   143
F3D144   144
F3D145   145
F3D146   146
F3D147   147
F3D148   148
F3D149   149
F3D150   150
F3D2     2
F3D3     3
F3D5     5
F3D6     6
F3D7     7
F3D8     8
F3D9     9
</code></pre>
</div>

<blockquote class="hands_on">
  <h3 id="-hands-on"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on</h3>

  <ul>
    <li><strong>Corr.axes</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“axes” to axes output from Nmds in 3 dimension</li>
        <li>“Generate Collector Curvers for” to Metadata table</li>
        <li>“metadata table” to <code class="highlighter-rouge">mouse.dpw.metadata</code></li>
        <li>“method” to <code class="highlighter-rouge">Spearman</code></li>
        <li>“numaxes” to <code class="highlighter-rouge">3</code></li>
      </ul>
    </li>
  </ul>

  <p>This will output a file like the following:</p>

  <div class="highlighter-rouge"><pre class="highlight"><code>Feature    axis1       p-value      axis2       p-value     axis3       p-value     length
dpw        0.205263    0.383832    -0.292982    0.213861    0.821053    0.000016    0.895600
</code></pre>
  </div>

  <p>Indicating that as the dpw increases, the communities shift to in the positive direction along axis 3.</p>

  <p>Another tool we can use is <code class="highlighter-rouge">get.communitytype</code> to see whether our data can be partitioned in to separate
community types</p>

  <!-- TODO: add this tool to mothur suite -->
  <ul>
    <li><strong>Get.communitytype</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“shared” to Subsample.shared file</li>
        <li>“output logfile?” to <code class="highlighter-rouge">yes</code></li>
      </ul>
    </li>
  </ul>

</blockquote>

<p>In logfile we find the following output:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>K    NLE        logDet    BIC         AIC         Laplace
1    9612.15    522.97    10070.01    9923.15     9587.84
2    9688.76    464.05    10605.95    10311.76    9348.28
3    10329.39   329.18    11705.91    11264.39    9634.77
4    11026.12   97.78     12861.98    12273.12    9929.10
5    11662.52  -250.61    13957.71    13221.52    10104.59
</code></pre>
</div>

<p>We see that the minimum Laplace value is for a K value of 2 (9348.28). This indicates that our samples
belonged to two community types. Opening the <code class="highlighter-rouge">design</code> output we see that all of the late samples and the Day 0
sample belonged to Partition_1 and the other early samples belonged to Partition_2. We can look at the
<code class="highlighter-rouge">summary</code> output to see which OTUs were most responsible for separating the communities:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>OTU        P0.mean  P1.mean  P1.lci  P1.uci  P2.mean  P2.lci  P2.uci  Difference   CumFraction
Otu0006    3.36     10.48    9.17    11.97   0.46     0.28    0.78    10.01        0.15
Otu0014    6.17     8.45     7.35    9.72    3.76     2.98    4.73    4.70         0.22
Otu0002    5.63     7.14     6.17    8.25    3.83     3.05    4.81    3.31         0.27
Otu0008    4.01     2.92     2.41    3.54    5.85     4.80    7.12    2.92         0.31
Otu0019    2.07     3.48     2.90    4.18    0.94     0.63    1.40    2.54         0.35
...
</code></pre>
</div>

<p>Again we can cross reference these OTU labels with the consensus classifications in the taxonomy file to get
the names of these organisms.</p>

<blockquote class="question">
  <h3 id="-question-11"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

  <p>What organisms were the top 5 contributing OTUs classified as?</p>

  <details>
  <summary> Click to view answer</summary>
  Note down the names of the top 5 OTUs as output by thesummary output of get.communitytype.
  Then look at the taxonomy file output by Classify.otu. <br /><br />

  In our example these top 5 OTUs were classified
  as belonging to Porphyromonadaceae (top 3 OTUs), Alistipes and Lactobacillus.
</details>
</blockquote>

<h2 id="population-level-analysis">Population-level Analysis</h2>

<p>In addition to the use of <code class="highlighter-rouge">corr.axes</code> and <code class="highlighter-rouge">get.communitytype</code> we have several tools to differentiate between
different groupings of samples. The first we’ll demonstrate is <code class="highlighter-rouge">metastats</code>, which is a non-parametric T-test
that determines whether there are any OTUs that are differentially represented between the samples from early and late in this study.</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-t-test"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: T-test</h3>

  <ul>
    <li><strong>Metastats</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“shared” to Subsample.shared</li>
        <li>“design” to <code class="highlighter-rouge">mouse.time.design</code></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Looking at the first 5 OTUs from <code class="highlighter-rouge">Late-Early</code> output file we see the following:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>OTU        mean(group1)  variance(group1)  stderr(group1)  mean(group2)  variance(group2)  stderr(group2)  p-value
Otu0001    0.026104      0.000079          0.002807        0.011304      0.000031          0.001856        0.000999
Otu0002    0.072869      0.000101          0.003176        0.041946      0.000208          0.004805        0.000999
Otu0003    0.015261      0.000023          0.001531        0.002182      0.000003          0.000539        0.000999
Otu0004    0.029451      0.000064          0.002536        0.020427      0.000140          0.003947        0.074925
Otu0005    0.068139      0.000087          0.002957        0.070058      0.000163          0.004254        0.729271
</code></pre>
</div>

<p>These data tell us that OTUs 1, 2, and 3 was significantly different between the early and late samples.</p>

<blockquote class="question">
  <h3 id="-question-12"><i class="fa fa-question-circle" aria-hidden="true"></i> Question</h3>

  <p>Which of the top 10 OTUs in your output were significantly different between early and late samples?</p>

  <details>
 <summary> Click to view answer</summary>
 Looking at the p-value cut-off and using your favorite cutoff threshold (say 0.01).
 Answer to the question is all OTUs with a value lower than this threshold. Note that these OTU labels may
 be different for you and may very between one repetition of this tutorial to the next, and therefore may
 vary between you and your neighbour as well.
</details>
</blockquote>

<p>Another non-parametric tool we can use as an alternative to metastats is lefse:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-lefse"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Lefse</h3>

  <ul>
    <li><strong>Lefse</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“shared” to Subsample.shared</li>
        <li>“design” to <code class="highlighter-rouge">mouse.time.design</code></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>Looking at the top of the lefse summary file we see:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>OTU        LogMaxMean  Class   LDA         pValue
Otu0001    4.41671     Late    3.91585    0.000601825
Otu0002    4.86254     Late    4.20329    0.000695271
Otu0003    4.18358     Late    3.82749    0.00022674
Otu0004    4.4691      -
Otu0005    4.84546     -
</code></pre>
</div>

<p>Again, OTUs 1, 2, and 3 are significantly different between the two groups and are significantly elevated in the
late samples</p>

<p>Finally, Mothur has an implementation of the random forest algorithm build into her as classify.rf. This will tell
us which features (i.e. OTUs) are useful in discriminating between the two groups of samples:</p>

<blockquote class="hands_on">
  <h3 id="-hands-on-classifyrf"><i class="fa fa-pencil" aria-hidden="true"></i> Hands-on: Classify.rf</h3>

  <ul>
    <li><strong>Classify.rf</strong> <i class="fa fa-wrench" aria-hidden="true"></i> with the following parameters
      <ul>
        <li>“shared” to Subsample.shared</li>
        <li>“design” to <code class="highlighter-rouge">mouse.time.design</code></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>in the logfile we see:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Creating 100 (th) Decision tree
numCorrect = 19
forrestErrorRate = 0
confusion matrix:
        Early    Late    time
Early   9        0       0
Late    0        10      0
time    0        0       0
</code></pre>
</div>

<p>We can ignore the time row and column and see that our samples were all correctly assigned to the proper groups.
Looking at <code class="highlighter-rouge">summary</code> output, we see the top 10 OTUs that resulted in the greatest mean decrease in activity were:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>OTU        Mean decrease accuracy
Otu0038    0.21
Otu0003    0.15
Otu0091    0.14
Otu0096    0.13
Otu0024    0.12
Otu0006    0.1
Otu0011    0.1
Otu0015    0.09
Otu0082    0.08
Otu0042    0.07
</code></pre>
</div>

<h1 class="no_toc" id="conclusion">Conclusion</h1>

<p>You have now seen how to perform the Schloss lab’s Standard Operating Procedure (SOP) for MiSeq data.
You have worked your way through the following pipeline:</p>

<p><img src="../../images/mothur_sop_pipeline.jpg" alt="Mothur sop tutorial pipeline" /></p>


        
        <blockquote class="key_points">
            <h3><i class="fa fa-key" aria-hidden="true"></i> Key points</h3>

            <ul>
                
                <li>16S rRNA gene sequencing analysis results depend on the many algorithms used and their settings</li>
                
                <li>Quality control and cleaning of your data is a crucial step in order to obtain optimal results</li>
                
                <li>Adding a mock community to serve as a control sample can help you asses the error rate of your experimental setup</li>
                
                <li>We can explore alpha and beta diversities using Krona and Phinch for dynamic visualizations</li>
                
            </ul>
        </blockquote>
        

        
        <h1>Useful literature</h1>
        <p>Further information, including links to documentation and original publications, regarding the tools, analysis techniques and the interpretation of results described in this tutorial can be found <a href="/training-material/topics/metagenomics#references">here</a>.</p>
        

        <h3><i class="fa fa-thumbs-up" aria-hidden="true"></i> Congratulations on successfully completing this tutorial!</h3>

        <hr>

        <blockquote class="overview">
            <h3><i class="fa fa-comments-o" aria-hidden="true"></i> Help us improve this content!</h3>
            Please take a moment to fill in the Galaxy Training Network
            <a href="https://tinyurl.com/GTNfeedback">Feedback Form</a>.
            Your feedback helps us improve this tutorial and will be considered
            in future revisions.
        </blockquote>
    </section>
</div>


<footer>
    <div class="container">
        <p>
            This material is the result of a collaborative work. Thanks to the
            <a href="https://wiki.galaxyproject.org/Teach/GTN">Galaxy Training Network</a>
            and all the <a href="/training-material/hall-of-fame">contributors</a> (Saskia Hiltemann, Bérénice Batut)!
        </p>
        <p>
            Found a typo? Something is wrong in this tutorial? Edit it on
            <a href="https://github.com/galaxyproject/training-material/tree/master/topics/metagenomics/tutorials/mothur-miseq-sop/tutorial.md">GitHub</a>.
        </p>
    </div>
</footer>

    </body>
    <script type="text/javascript" src="/training-material/assets/js/jquery.slim.min.js"></script>
    <script type="text/javascript" src="/training-material/assets/js/popper.min.js"></script>
    <script type="text/javascript" src="/training-material/assets/js/bootstrap.min.js?v=3"></script>
    <script type="text/javascript" src="/training-material/assets/js/details-element-polyfill.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="/training-material/assets/js/main.js"></script>
</html>
